{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db71abe4",
   "metadata": {},
   "source": [
    "### Libs and data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e975d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pathlib\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, TextVectorization, Embedding, GRU, Bidirectional\n",
    "from tensorflow.keras.layers import Layer, MultiHeadAttention, LayerNormalization, concatenate\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a1f1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "MAX_SEQ_LENGTH = 25\n",
    "VOCAB_SIZE = 15_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faebaacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the file\n",
    "path_to_zip = tf.keras.utils.get_file('spa-eng.zip', extract=True,\n",
    "                                      origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip')\n",
    "\n",
    "PATH_TO_DATASET = pathlib.Path(path_to_zip).parent / 'spa-eng' / 'spa.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64107fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chars in dataset: 7919056\n"
     ]
    }
   ],
   "source": [
    "def tf_lower_and_split_punct(text):\n",
    "    text = tf_text.normalize_utf8(text, 'NFKD')  # Split accecented characters.\n",
    "    text = tf.strings.lower(text)\n",
    "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')  # Keep space, a to z, [], and select punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')  # Add spaces around punctuation.\n",
    "    text = tf.strings.strip(text)  # Strip whitespace.\n",
    "\n",
    "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "    return text\n",
    "\n",
    "def split_pair(pair):\n",
    "    return [p[0] for p in pair], [p[1] for p in pair]\n",
    "\n",
    "def load_data(path):\n",
    "    text = path.read_text(encoding='utf-8')\n",
    "    print(f\"Chars in dataset: {len(text)}\")\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    pairs = [line.split('\\t') for line in lines]\n",
    "    return pairs\n",
    "\n",
    "\n",
    "pairs = load_data(PATH_TO_DATASET)\n",
    "random.Random(2006).shuffle(pairs)  # 118_964 = 85_000 + 10_000 + 23 964\n",
    "train_pairs, val_pairs, test_pairs = pairs[:85_000], pairs[85_000:95_000], pairs[95_000:]\n",
    "\n",
    "ds_text = tf.data.Dataset.from_tensor_slices(split_pair(pairs)).shuffle(BATCH_SIZE * 100).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9d2ce4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It was good working with you.', 'Estuvo bien trabajar contigo.']\n",
      "[\"Don't touch my camera.\", 'No toques mi cámara.']\n",
      "[\"I know what I'm saying.\", 'Yo sé lo que estoy diciendo.']\n",
      "['I think they know you.', 'Yo creo que ellas te conocen.']\n",
      "['I like fishing.', 'Me gusta la pesca.']\n",
      "tf.Tensor(b\"Don't leave things half finished.\", shape=(), dtype=string)\n",
      "tf.Tensor(b'Tom and Mary are going to a dance tomorrow evening.', shape=(), dtype=string)\n",
      "tf.Tensor(b'My aunt brought me some flowers.', shape=(), dtype=string)\n",
      "tf.Tensor(b'No dejes las cosas a medias.', shape=(), dtype=string)\n",
      "tf.Tensor(b'Tom y Mary van a bailar ma\\xc3\\xb1ana por la tarde.', shape=(), dtype=string)\n",
      "tf.Tensor(b'Mi t\\xc3\\xada me trajo algunas flores.', shape=(), dtype=string)\n",
      "\n",
      "¿Todavía está en casa?\n",
      "[START] ¿ todavia esta en casa ? [END]\n"
     ]
    }
   ],
   "source": [
    "print(*pairs[:5], sep='\\n')\n",
    "for example_input_batch, example_target_batch in ds_text.take(1):\n",
    "    print(*example_input_batch[:3], sep='\\n')\n",
    "    print(*example_target_batch[:3], sep='\\n')\n",
    "    print()\n",
    "\n",
    "example_text = tf.constant(\"¿Todavía está en casa?\", dtype=tf.string)\n",
    "print(example_text.numpy().decode())\n",
    "print(tf_lower_and_split_punct(example_text).numpy().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c053952f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35.\n",
      " 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50.] [    0     0     0     0    48  2822  9586 17620 20897 19935 16457 11350\n",
      "  7737  4670  3061  1817  1098   727   446   259   117    77    74    59\n",
      "    19    26    15    13    13     3     2     0     0     2     2     6\n",
      "     0     2     2     0     0     0     0     0     0     0     1     0\n",
      "     0     1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cap_lens = [len(p[0].split()) + 3 for p in pairs]\n",
    "counts, bins = np.histogram(cap_lens, 50, range=(0., 50.))\n",
    "print(bins, counts)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,  3), layout='constrained')\n",
    "plt.hist(bins[:-1], bins, weights=counts, density=True, facecolor='C0', alpha=0.75)\n",
    "ax.set_xlabel('Length captions')\n",
    "ax.set_ylabel('Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efab3d6",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea41fc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom', 'a', '?', 'is', 'he', 'in', 'of', 'that', 'it']\n",
      "['', '[UNK]', '[START]', '[END]', '.', 'que', 'de', 'el', 'a', 'no', 'tom', 'la', '?', '¿', 'en', 'es', 'un', 'se']\n"
     ]
    }
   ],
   "source": [
    "source_vectorization = tf.keras.layers.TextVectorization(  # English\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=VOCAB_SIZE, output_mode=\"int\",\n",
    "    output_sequence_length=MAX_SEQ_LENGTH)\n",
    "\n",
    "source_vectorization.adapt([p[0] for p in train_pairs])\n",
    "eng_vocab = source_vectorization.get_vocabulary()\n",
    "eng_index_lookup = dict(zip(range(len(eng_vocab)), eng_vocab))\n",
    "print(eng_vocab[:18])  # Here are the first 18 words from the vocabulary\n",
    "\n",
    "\n",
    "target_vectorization = tf.keras.layers.TextVectorization(  # Spanish\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=VOCAB_SIZE, output_mode=\"int\",\n",
    "    output_sequence_length=MAX_SEQ_LENGTH+1)\n",
    "\n",
    "target_vectorization.adapt([p[1] for p in train_pairs])\n",
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "print(spa_vocab[:18])  # Here are the first 18 words from the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "628cb346",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  2  27 179 253 786 403   4   3   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  2   9  40  32  29  75   7  10 740 166 664   4   3   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]], shape=(2, 25), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGzCAYAAAAFROyYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0RUlEQVR4nO3deXRUZbb38V9VJpBMhiEhQhAUQUVQo0IEW4Q0ARVBQBFtG702qB1sAW29OCEuWxzBEWi9NrzajQPeC7S2qIiC1zagTO2AICgCGhIUSYUpYz3vHzR1LRI8p0Il9VTx/axVa5FTO+fsVDfbzZNnn+MxxhgBAABYxBvpBAAAAA5FgwIAAKxDgwIAAKxDgwIAAKxDgwIAAKxDgwIAAKxDgwIAAKxDgwIAAKxDgwIAAKxDgwJJksfj0bhx4yKdBgCEZOnSpfJ4PHrttdcinQrCjAYlink8HlevpUuXRjrVkPTt21fdunULOnb88ccHfh6v16v09HSddtppGjt2rFasWBGhTAHMmTMn8Hfzww8/rPO+MUbt27eXx+PRxRdfHIEMEa3iI50AGu7FF18M+vqFF17Q4sWL6xw/+eSTmzKtRnP66afrlltukSTt3r1bX375pebNm6fnnntOEyZM0LRp0yKcIXD0atasmebOnas+ffoEHV+2bJm+++47JSUlRSgzRCsalCj2m9/8Jujr5cuXa/HixXWOx4rjjjuuzs/20EMP6corr9T06dPVuXNn3XjjjRHKDji6XXjhhZo3b56efPJJxcf/339a5s6dq9zcXP34448RzA7RiF/xxLi9e/fqlltuUfv27ZWUlKQuXbro0UcflZuHWN9///3yer166qmnAscWLVqk8847Ty1atFBKSoouuugiffHFF0Hfd8011yg5OVnff/+9hg4dquTkZLVu3Vq33nqramtrw/rzNW/eXC+++KIyMjL0pz/9Kejnevnll5Wbm6uUlBSlpqbqtNNO0xNPPBHW6wM4YNSoUdq5c6cWL14cOFZVVaXXXntNV155ZZ34Rx99VOeee65atmyp5s2bKzc3t959JIsXL1afPn2Unp6u5ORkdenSRXfccccv5lJZWamLL75YaWlp+uijj478h0NE0KDEMGOMLrnkEk2fPl0DBw7UtGnT1KVLF/3xj3/UxIkTf/F777rrLt1zzz3685//rJtuuknSgV8pXXTRRUpOTtZDDz2ku+++W+vWrVOfPn307bffBn1/bW2tCgoK1LJlSz366KM6//zz9dhjj+nZZ58N+8+ZnJysSy+9VN9//73WrVsn6UBRGzVqlI499lg99NBDevDBB9W3b1/985//DPv1ARzYJ5aXl6eXXnopcGzRokXy+Xy64oor6sQ/8cQTOuOMM3TffffpgQceUHx8vC677DL94x//CMR88cUXuvjii1VZWan77rtPjz32mC655JJf/Hu8f/9+DR48WB999JHeffddnXvuueH9QdF0DGJGYWGh+fn/pAsWLDCSzP333x8UN2LECOPxeMymTZsCxySZwsJCY4wxt9xyi/F6vWbOnDmB93fv3m3S09PNmDFjgs5VUlJi0tLSgo6PHj3aSDL33XdfUOwZZ5xhcnNzHX+O888/35x66qlBxzp06GAuuuiiw37P9OnTjSSzcOFCY4wxN998s0lNTTU1NTWO1wPQcLNnzzaSzCeffGKefvppk5KSYvbt22eMMeayyy4zF1xwgTGm7t/hgzEHVVVVmW7dupl+/foFjh38e/3DDz8c9vrvv/++kWTmzZtndu/ebc4//3zTqlUrs2bNmjD+lIgEVlBi2Jtvvqm4uDj94Q9/CDp+yy23yBijRYsWBR03xmjcuHF64okn9Ne//lWjR48OvLd48WKVlZVp1KhR+vHHHwOvuLg49ezZU++//36d699www1BX5933nn65ptvwvgT/p/k5GRJBzbPSlJ6err27t0btNwMoHFdfvnl2r9/v9544w3t3r1bb7zxRr2/3pEO/Hr2oF27dsnn8+m8887T6tWrA8fT09MlSQsXLpTf7//Fa/t8Pg0YMEDr16/X0qVLdfrppx/xz4PIYpNsDNuyZYuys7OVkpISdPzgVM+WLVuCjr/wwgvas2ePZs6cqVGjRgW9t3HjRklSv3796r1Wampq0NfNmjVT69atg44de+yx2rVrV+g/iAt79uyRpMDP+vvf/16vvvqqBg0apOOOO04DBgzQ5ZdfroEDBzbK9QFIrVu3Vn5+vubOnat9+/aptrZWI0aMqDf2jTfe0P3336+1a9eqsrIycNzj8QT+PHLkSP3Xf/2Xfve73+k///M/1b9/fw0bNkwjRoyQ1xv87+vx48eroqJCa9as0amnnto4PyCaFCsoCOjdu7cyMzP19NNP66effgp67+C/Xl588UUtXry4zmvhwoVB8XFxcU2WtyR9/vnnkqQTTzxRktSmTRutXbtWf//733XJJZfo/fff16BBg4JWhQCE35VXXqlFixZp1qxZGjRoUGAV5Of+93//V5dccomaNWumGTNm6M0339TixYt15ZVXBm10b968uT744AO9++67uvrqq/Xpp59q5MiR+vWvf11nw/2QIUNkjNGDDz7ouNqC6ECDEsM6dOig4uLiwK89Dlq/fn3g/Z878cQT9c4776i4uFgDBw4M+r4TTjhB0oH/8Ofn59d59e3bt3F/mF+wZ88ezZ8/X+3btw+650tiYqIGDx6sGTNm6Ouvv9b111+vF154QZs2bYpYrkCsu/TSS+X1erV8+fLD/nrnv//7v9WsWTO9/fbb+o//+A8NGjRI+fn59cZ6vV71799f06ZN07p16/SnP/1J7733Xp1fKw8dOlR/+ctfNHfuXBUWFob950LTo0GJYRdeeKFqa2v19NNPBx2fPn26PB6PBg0aVOd7unfvrjfffFNffvmlBg8erP3790uSCgoKlJqaqgceeEDV1dV1vu+HH35onB/Cwf79+3X11Vfrp59+0p133hlYHt65c2dQnNfrVffu3SUpaDkZQHglJydr5syZuvfeezV48OB6Y+Li4uTxeIJWQb799lstWLAgKO7QlVxJgb0l9f09/u1vf6snn3xSs2bN0u23397wHwJWYA9KDBs8eLAuuOAC3Xnnnfr222/Vo0cPvfPOO1q4cKHGjx8fWBU5VK9evbRw4UJdeOGFGjFihBYsWKDU1FTNnDlTV199tc4880xdccUVat26tbZu3ap//OMf6t27d51GKNy+//57/fWvf5V0YNVk3bp1mjdvnkpKSnTLLbfo+uuvD8T+7ne/008//aR+/fqpXbt22rJli5566imdfvrpMXNnXcBWTr9KveiiizRt2jQNHDhQV155pXbs2KFnnnlGJ554oj799NNA3H333acPPvhAF110kTp06KAdO3ZoxowZateuXZ071h40btw4lZeX684771RaWprjPVNgscgOESGcDh0zNubAePCECRNMdna2SUhIMJ07dzaPPPKI8fv9QXH62ZjxQQsXLjTx8fFm5MiRpra21hhzYKSvoKDApKWlmWbNmpkTTjjBXHPNNWblypWB7xs9erRp0aJFnfwmT55cJ7/6HG7MWJKRZDwej0lNTTWnnnqqGTNmjFmxYkWdc7z22mtmwIABpk2bNiYxMdHk5OSY66+/3mzfvt3x+gDc+/mY8S85dMz4+eefN507dzZJSUmma9euZvbs2XVqxJIlS8yQIUNMdna2SUxMNNnZ2WbUqFHmq6++CsT8fMz452677TYjyTz99NNh+knR1DzGuLilKAAAQBNiDwoAALAODQoAALAODQoAALAODQoAALAODQoAALAODQoAALCOdTdq8/v9Ki4uVkpKStBDowA0HWOMdu/erezs7DoPZbMVtQOIrHDXDesalOLiYrVv3z7SaQCQtG3bNrVr1y7SabhC7QDsEK66YV2DkpKSIknqowsVr4RGv54n3vka5pCnZtYf5OLpmR4XHaWb87jV1NdDzKhRtT7Um4G/j9HgYK5bVh+v1OToWPU52l160mmRTgFhFO66YV2DcnBpNl4Jivc0QYPi4hrGzX/oFaYGxc153Grq6yF2/Pv+0tH0q5KDuaYme5WaEhfhbOBGU9R4NKEw1w3+mQEAAKxDgwIAAKxj3a94wskT57zMG679JfFdOzvG1Kzf6BjjPeYYxxj/vn2OMZLYXwKgURRk94h0CjgKsIICAACsQ4MCAACsQ4MCAACsQ4MCAACsQ4MCAACsE7VTPN6kZs5Bp57gGGKaubhR0EdrHUPcTOi44XpCB8BRg6kZHI1YQQEAANahQQEAANahQQEAANahQQEAANahQQEAANaJ2ikef2WFc9DqLxxD4lu2dIz5Zsq5jjE5kz9yzgcAGuDt4n85xjDpg1jDCgoAALBOyA3K999/r9/85jdq2bKlmjdvrtNOO00rV64MvG+M0T333KO2bduqefPmys/P18aN4blHCIDoRe0AEIqQGpRdu3apd+/eSkhI0KJFi7Ru3To99thjOvbYYwMxDz/8sJ588knNmjVLK1asUIsWLVRQUKCKChe/kgEQk6gdAEIV0h6Uhx56SO3bt9fs2bMDxzp27Bj4szFGjz/+uO666y4NGTJEkvTCCy8oMzNTCxYs0BVXXBGmtAFEE2oHgFCFtILy97//XWeddZYuu+wytWnTRmeccYaee+65wPubN29WSUmJ8vPzA8fS0tLUs2dPFRUV1XvOyspKlZeXB70AxBZqB4BQhbSC8s0332jmzJmaOHGi7rjjDn3yySf6wx/+oMTERI0ePVolJSWSpMzMzKDvy8zMDLx3qKlTp2rKlCkNTP/I1ezc6Rhz/AOrnU/k4tlAriaPgBgUi7XDNkz6INaEtILi9/t15pln6oEHHtAZZ5yhsWPHasyYMZo1a1aDE5g0aZJ8Pl/gtW3btgafC4CdqB0AQhVSg9K2bVudcsopQcdOPvlkbd26VZKUlZUlSSotLQ2KKS0tDbx3qKSkJKWmpga9AMQWageAUIXUoPTu3VsbNmwIOvbVV1+pQ4cOkg5sesvKytKSJUsC75eXl2vFihXKy8sLQ7oAohG1A0CoQtqDMmHCBJ177rl64IEHdPnll+vjjz/Ws88+q2effVaS5PF4NH78eN1///3q3LmzOnbsqLvvvlvZ2dkaOnRoY+QPIApQOwCEKqQG5eyzz9b8+fM1adIk3XffferYsaMef/xxXXXVVYGY2267TXv37tXYsWNVVlamPn366K233lKzZs6bSAHEJmoHgFB5jDEm0kn8XHl5udLS0tRXQxTvSThsnDcx0fFc/uoa5wsav2NIXMaxjjG1u3xhuZYb3ubNXcWZqirHGE/84T/jg5g+OvrUmGot1UL5fL6o2dtxsHbs+qqTUlPiIp0OwoTJo+gR7rrBs3gAAIB1aFAAAIB1aFAAAIB1aFAAAIB1QprisYmbDbDeZknO59m/3zmmfI9jzE/X9XKMyfivjxxj3HCTs1umtjZs5wJgNzacIpqwggIAAKxDgwIAAKxDgwIAAKxDgwIAAKxDgwIAAKwTtVM8bm4b72baJb5lS8eYmp07HWPa/H2j83kcI6Q9VzhPAyW/vNzFmQAg2NvF/wrLeZgGQlNgBQUAAFiHBgUAAFiHBgUAAFiHBgUAAFiHBgUAAFgneqd4PM69VVxqimOMmwkdN2p2/BCW8zChA6AhmKxBrGEFBQAAWIcGBQAAWIcGBQAAWIcGBQAAWIcGBQAAWCd6p3jcPItnzx7HmLi0NMeYWp/POR8XU0XxGcc6xoRrqgjA0YXn7CDWsIICAACsQ4MCAACsQ4MCAACsQ4MCAACsE72bZF3wJCU5xlT07OwYk/DOSueLudi0ywZYAA3BxlUcjVhBAQAA1qFBAQAA1qFBAQAA1qFBAQAA1qFBAQAA1onaKR5PXJxjjH9/hWOMmwkdT3yCY4ypqXaMAYCGcHMbeyZ9EGtYQQEAANahQQEAANahQQEAANahQQEAANahQQEAANaJ2ike7zHHOMZ4kls4xtRsL3G+VjPnZ/pIzjG1e/a4OA8AhI5JH8QaVlAAAIB1aFAAAIB1aFAAAIB1aFAAAIB1aFAAAIB1onaKRy6exeNmQseN2r37HGPiO+Y4n6jbCc4xKz5zjjF+5xgAOISbSZ9wYWIIR4oVFAAAYJ2QGpR7771XHo8n6NW1a9fA+xUVFSosLFTLli2VnJys4cOHq7S0NOxJA4gu1A4AoQp5BeXUU0/V9u3bA68PP/ww8N6ECRP0+uuva968eVq2bJmKi4s1bNiwsCYMIDpROwCEIuQ9KPHx8crKyqpz3Ofz6fnnn9fcuXPVr18/SdLs2bN18skna/ny5erVq9eRZwsgalE7AIQi5BWUjRs3Kjs7W506ddJVV12lrVu3SpJWrVql6upq5efnB2K7du2qnJwcFRUVHfZ8lZWVKi8vD3oBiD3UDgChCGkFpWfPnpozZ466dOmi7du3a8qUKTrvvPP0+eefq6SkRImJiUpPTw/6nszMTJWUHH6aZurUqZoyZUrIideWlTkHeZz7r7gWzs/02TX0NMeYjOUufl/uZkLHheoBZ7mKS3hnZViuBxwpm2oHgOgQUoMyaNCgwJ+7d++unj17qkOHDnr11VfVvHnzBiUwadIkTZw4MfB1eXm52rdv36BzAbATtQNAqI5ozDg9PV0nnXSSNm3apKysLFVVVanskJWN0tLSen/vfFBSUpJSU1ODXgBiG7UDgJMjalD27Nmjr7/+Wm3btlVubq4SEhK0ZMmSwPsbNmzQ1q1blZeXd8SJAogd1A4ATkL6Fc+tt96qwYMHq0OHDiouLtbkyZMVFxenUaNGKS0tTdddd50mTpyojIwMpaam6qabblJeXh678IGjHLUDQKhCalC+++47jRo1Sjt37lTr1q3Vp08fLV++XK1bt5YkTZ8+XV6vV8OHD1dlZaUKCgo0Y8aMRkm8bLTzv6zS/9/hJwAO2jnceQOsm/Mou61zTJhuUc/mV0Qbm2rH0YzbzyOaeIwxJtJJ/Fx5ebnS0tLUV0MU70k4bFy4GpRwnSfeRYNSU7zdMQawQY2p1lItlM/ni5q9HQdrx66vOik1xflZXUcjGhQ0pnDXDZ7FAwAArEODAgAArEODAgAArEODAgAArBPywwJtkf7CirCcJ+PlNY4xbmZv/LvKHGPikpMdY2r37HFxNQAI3dvF/3KMYSMtbMEKCgAAsA4NCgAAsA4NCgAAsA4NCgAAsA4NCgAAsE7UTvF4E5xT91dVhSXGDf/+/c5BHvpBAHZzM+njBtNAOFL8FxMAAFiHBgUAAFiHBgUAAFiHBgUAAFiHBgUAAFgnaqd43EzfVA84yzGm+dotzherdX4aT83OnY4xJTf3cozJevwj53wAoJEwfQNbsIICAACsQ4MCAACsQ4MCAACsQ4MCAACsE7WbZD1xcY4xCe+sdIypcXGtuNO6Ogf9tMsxJPvPaxxjvJltHGNqSnc45wMADeDmVvdspEVTYAUFAABYhwYFAABYhwYFAABYhwYFAABYhwYFAABYJ2qneIzfNNm1aj9b7xjjiU9wjPHv3x+WGABoCKZvEE1YQQEAANahQQEAANahQQEAANahQQEAANahQQEAANaJ2ikeGX9YTuPmmT6mttb5PInOUzymptpFQs49ozcx0fk8krwZ6Y4xppVzjKspJhefo5ufLa51S8eYmu0lzudJSXGMqd292zEGiCVunrODpsFElTNWUAAAgHVoUAAAgHVoUAAAgHVoUAAAgHVoUAAAgHWid4onTNxM6HiTmjnG+Pftc4yJ73S8Y0zNN986X6uywjFGkvwupl3kJsYFN5+j5BzjZkLHDSZ0gIZhugS2YAUFAABYhwYFAABYhwYFAABYhwYFAABYhwYFAABYJ3qneFw818XN83o8Pbs7xvhXfOomI0c1m7c6xrh5hoybiSFJ8h5zjGMM0y4Afq4pn9fDxBB+yRGtoDz44IPyeDwaP3584FhFRYUKCwvVsmVLJScna/jw4SotLT3SPAHECOoGADca3KB88skn+vOf/6zu3YNXICZMmKDXX39d8+bN07Jly1RcXKxhw4YdcaIAoh91A4BbDWpQ9uzZo6uuukrPPfecjj322MBxn8+n559/XtOmTVO/fv2Um5ur2bNn66OPPtLy5cvDljSA6EPdABCKBjUohYWFuuiii5Sfnx90fNWqVaqurg463rVrV+Xk5KioqKjec1VWVqq8vDzoBSD2hLNuSNQOINaFvEn25Zdf1urVq/XJJ5/Uea+kpESJiYlKT08POp6ZmamSkvpvYT516lRNmTIl1DRcbYCNb93KMabGxQZY39V5jjFpLx6+kAbyaZXhGPPCmr87xvymc3/HGElSXJy7OKCRhbtuSEdQOwBEhZBWULZt26abb75Zf/vb39SsmfPzadyYNGmSfD5f4LVt27awnBeAHRqjbkjUDiDWhdSgrFq1Sjt27NCZZ56p+Ph4xcfHa9myZXryyScVHx+vzMxMVVVVqaysLOj7SktLlZWVVe85k5KSlJqaGvQCEDsao25I1A4g1oX0K57+/fvrs88+Czp27bXXqmvXrrr99tvVvn17JSQkaMmSJRo+fLgkacOGDdq6davy8px/TQIg9lA3ADRESA1KSkqKunXrFnSsRYsWatmyZeD4ddddp4kTJyojI0Opqam66aablJeXp169eoUvawBRg7oBoCHCfifZ6dOny+v1avjw4aqsrFRBQYFmzJgR7ssAiCHUDQCH8hhjTKST+Lny8nKlpaWpr4Yo3pNwROdyc6t3N7eNd3Oekz6ocYxZf1aVYwxggxpTraVaKJ/PFzV7Ow7Wjl1fdVJqChNs9eHW8mhM4a4bPCwQAABYhwYFAABYhwYFAABYhwYFAABYhwYFAABYJ+xjxjYxlZXOQR7nHs3NpM9XvcNzC+8fbzjXMabVrI/Cci0AR5e3i/8VlvMwDYSmwAoKAACwDg0KAACwDg0KAACwDg0KAACwDg0KAACwTtRO8cQlJzvG+Pfvdz6R8YchG2nR5hWOMW52vruZ0PGff6arnOI+dN6xb2prXZ3Lyf53OjrGHHPhd44xpqY6HOkAaEThmgZqSkweRR9WUAAAgHVoUAAAgHVoUAAAgHVoUAAAgHWidpNs7Z49zkEubmNfflWeY0zq34ocYy7s1tc5H+1yDnGRs3fZahfXkoyrqPBoPmCzY0xT5gOg8bDhFE2BFRQAAGAdGhQAAGAdGhQAAGAdGhQAAGAdGhQAAGCdqJ3iCRc3EzrxrVs5xtT88KNjjCcuzjHmqnVbHWP+dkqOY8yBC4an/+T28wB+rilvdc/E0NGLFRQAAGAdGhQAAGAdGhQAAGAdGhQAAGAdGhQAAGCd2J7iMX7HEDeTNbW7fOHIRqa21jHmr12Oc3Em5/OEFgcg2jHtgljDCgoAALAODQoAALAODQoAALAODQoAALAODQoAALBOTE/xeBMTHWP8VVUuzhSeaZi4tDQXl3K+licpydX1anbudBXnJC4lxTGmdvfusFwLQMM05fNxbMMEU2xiBQUAAFiHBgUAAFiHBgUAAFiHBgUAAFgnpjfJutoA63Hu0TxeTxiykfx79jjGxKWnO8bU/LTL1fXCtUmYDbAAGgObW/FLWEEBAADWoUEBAADWoUEBAADWoUEBAADWoUEBAADWiekpnvgTOznG1G7e4hhj/Mb5YsbvJiVH4bo9veT2Nv4AYgETMYg1rKAAAADrhNSgzJw5U927d1dqaqpSU1OVl5enRYsWBd6vqKhQYWGhWrZsqeTkZA0fPlylpaVhTxpAdKF2AAhVSA1Ku3bt9OCDD2rVqlVauXKl+vXrpyFDhuiLL76QJE2YMEGvv/665s2bp2XLlqm4uFjDhg1rlMQBRA9qB4BQeYwxLjZYHF5GRoYeeeQRjRgxQq1bt9bcuXM1YsQISdL69et18sknq6ioSL169XJ1vvLycqWlpamvhijek3AkqUXlHhTABjWmWku1UD6fT6mpqY1yjcaqHbu+6qTUlLhGydlm7EFBpIW7bjR4D0ptba1efvll7d27V3l5eVq1apWqq6uVn58fiOnatatycnJUVFR02PNUVlaqvLw86AUgdlE7ALgR8hTPZ599pry8PFVUVCg5OVnz58/XKaecorVr1yoxMVHphzxLJjMzUyUlJYc939SpUzVlypSQE/fEufgX0i6fY4j3lM6OMbWfrXeRkItej1UWHMVsqR2x6u3ifznGsMqCaBLyCkqXLl20du1arVixQjfeeKNGjx6tdevWNTiBSZMmyefzBV7btm1r8LkA2IvaASAUIa+gJCYm6sQTT5Qk5ebm6pNPPtETTzyhkSNHqqqqSmVlZUH/EiotLVVWVtZhz5eUlKSkpKTQMwcQVagdAEJxxPdB8fv9qqysVG5urhISErRkyZLAexs2bNDWrVuVl5d3pJcBEGOoHQB+SUgrKJMmTdKgQYOUk5Oj3bt3a+7cuVq6dKnefvttpaWl6brrrtPEiROVkZGh1NRU3XTTTcrLy3O9Cx9AbKJ2AAhVSA3Kjh079Nvf/lbbt29XWlqaunfvrrffflu//vWvJUnTp0+X1+vV8OHDVVlZqYKCAs2YMaNREgcQPagdAEJ1xPdBCbdw3gcl7pCpgPrUlpU5n8jFhI7H63GMcXM/lbjUFMeYWp/zdBJwJJriPijhdrTfB6UpMQ2E+lhzHxQAAIDGQoMCAACsQ4MCAACsQ4MCAACsQ4MCAACsE/KdZKNJ2CZ0XDz3x9TWOsYkvp/pGFPVd7tjDAA0FiZ0YAtWUAAAgHVoUAAAgHVoUAAAgHVoUAAAgHWidpNsfOtWjjE1P/zofCLjdwzZ/lpXx5isoescY6ouKHXOxwU3t/CXXG4SDhPvmac6xvhXf9EEmQA4Em8X/yvSKTQKNv9GH1ZQAACAdWhQAACAdWhQAACAdWhQAACAdWhQAACAdaJ2isfNhI43MdExxnNSR8eYrEvXu8rJyZ7Lz3GMSX5luWNMU07nuMWEDhAbmHaBLVhBAQAA1qFBAQAA1qFBAQAA1qFBAQAA1qFBAQAA1onaKR43/NU1jjGeLzc5xvzw+16OMa2f+cgxJv0952vVeMLYM7p4zhAA/Fy4nsXDNBCOFCsoAADAOjQoAADAOjQoAADAOjQoAADAOjQoAADAOjE9xePxepxjkpIcY9rO2+gY4z/mGMeYmh9/coxxM3nTbXWc83kkfX6mqzAAAKzDCgoAALAODQoAALAODQoAALAODQoAALBOTG+SNX7jHLO/wjHGv2+fY4w3qZlzTHMXMelpjjGf/76NY8wB4bllNQAATY0VFAAAYB0aFAAAYB0aFAAAYB0aFAAAYB0aFAAAYJ2YnuJxc9t4ecLTo/mrqpyDXOTj8brIZ/l2FxkBQOMoyO4R6RRwFGAFBQAAWIcGBQAAWIcGBQAAWIcGBQAAWIcGBQAAWCdqp3g8cXGOMaa21vlELiZrim8/1zEm+6GPnK/lwoaZJznGnHj16rBcCwAAW7GCAgAArBNSgzJ16lSdffbZSklJUZs2bTR06FBt2LAhKKaiokKFhYVq2bKlkpOTNXz4cJWWloY1aQDRhdoBIFQhNSjLli1TYWGhli9frsWLF6u6uloDBgzQ3r17AzETJkzQ66+/rnnz5mnZsmUqLi7WsGHDwp44gOhB7QAQqpD2oLz11ltBX8+ZM0dt2rTRqlWr9Ktf/Uo+n0/PP/+85s6dq379+kmSZs+erZNPPlnLly9Xr169wpc5gKhB7QAQqiPag+Lz+SRJGRkZkqRVq1apurpa+fn5gZiuXbsqJydHRUVF9Z6jsrJS5eXlQS8AsY3aAcBJg6d4/H6/xo8fr969e6tbt26SpJKSEiUmJio9PT0oNjMzUyUlJfWeZ+rUqZoyZUrI1zd+E/L31MebmOgYkzNnk2NMTTiSERM6iH2Rrh2xiufjINY0eAWlsLBQn3/+uV5++eUjSmDSpEny+XyB17Zt247ofADsRu0A4EaDVlDGjRunN954Qx988IHatWsXOJ6VlaWqqiqVlZUF/UuotLRUWVlZ9Z4rKSlJSUlJDUkDQJShdgBwK6QVFGOMxo0bp/nz5+u9995Tx44dg97Pzc1VQkKClixZEji2YcMGbd26VXl5eeHJGEDUoXYACFVIKyiFhYWaO3euFi5cqJSUlMDvhtPS0tS8eXOlpaXpuuuu08SJE5WRkaHU1FTddNNNysvLYxc+cBSjdgAIVUgNysyZMyVJffv2DTo+e/ZsXXPNNZKk6dOny+v1avjw4aqsrFRBQYFmzJgRlmQBRCdqB4BQeYwx4RmHCZPy8nKlpaWpr4Yo3pNw+ECP82+nvAnO/ZcnuYVjTO1PuxxjwsXNVJG/2uXMkIvnDMWlpDjG1O7e7e56iBk1plpLtVA+n0+pqamRTseVg7Vj11edlJri/KwuRAemk6JHuOsGz+IBAADWoUEBAADWoUEBAADWoUEBAADWafCt7iPOxQbQXSNzHWPSXqz/OR8/V/Prsxxj4hevdIxxw19VFZbzuMUGWCA2sJkUsYYVFAAAYB0aFAAAYB0aFAAAYB0aFAAAYB0aFAAAYJ3oneJxwc2Ezg+F5zrGtH7mo3CkAwANwoQOjkasoAAAAOvQoAAAAOvQoAAAAOvQoAAAAOvQoAAAAOvE9BSPG21mrXCM8RxzjGOMf3+FY4w3wcXHHRfn4lr7nc8DIGa8XfyvSKcQhKkiNAVWUAAAgHVoUAAAgHVoUAAAgHVoUAAAgHVoUAAAgHVieoonvk1rx5iaHT84xsS1cDHFs2+fc0xVlWMMADQEkzWINaygAAAA69CgAAAA69CgAAAA69CgAAAA60TtJllvYqJjjJsNsO4u5tzHxbds6RhTs3NnOLIBgDrc3A6fjbSIJqygAAAA69CgAAAA69CgAAAA69CgAAAA69CgAAAA60TtFI+b28Z74hMcY0xtrWNMTekOx5g9I3s5xiS/whQPAABusIICAACsQ4MCAACsQ4MCAACsQ4MCAACsQ4MCAACsE7VTPK4Yv2OIm2f6KM65j0t+ZbnzadLTHWNqy8qc8wGABuB5PYgmrKAAAADr0KAAAADr0KAAAADr0KAAAADr0KAAAADrxPQUj7d5c8cYf0Wl84lqqp1jPM69XpNP6LjIyc2kU7ieaeTmWgAiy82kTzRiOin6sIICAACsE3KD8sEHH2jw4MHKzs6Wx+PRggULgt43xuiee+5R27Zt1bx5c+Xn52vjxo3hyhdAFKJuAAhVyA3K3r171aNHDz3zzDP1vv/www/rySef1KxZs7RixQq1aNFCBQUFqqioOOJkAUQn6gaAUIW8B2XQoEEaNGhQve8ZY/T444/rrrvu0pAhQyRJL7zwgjIzM7VgwQJdccUVR5YtgKhE3QAQqrDuQdm8ebNKSkqUn58fOJaWlqaePXuqqKio3u+prKxUeXl50AvA0aMhdUOidgCxLqxTPCUlJZKkzMzMoOOZmZmB9w41depUTZkyJZxpBNTu3ecYE9+hvWNMzbdbwpGOq+f++KuqwnItSWGbmjFuppiABmpI3ZAat3YczZh2gS0iPsUzadIk+Xy+wGvbtm2RTglAFKB2ALEtrA1KVlaWJKm0tDToeGlpaeC9QyUlJSk1NTXoBeDo0ZC6IVE7gFgX1galY8eOysrK0pIlSwLHysvLtWLFCuXl5YXzUgBiBHUDQH1C3oOyZ88ebdq0KfD15s2btXbtWmVkZCgnJ0fjx4/X/fffr86dO6tjx466++67lZ2draFDh4YzbwBRhLoBIFQhNygrV67UBRdcEPh64sSJkqTRo0drzpw5uu2227R3716NHTtWZWVl6tOnj9566y01a9YsfFmHUbg2wMZntnG+VukO5/Mc38H5PGHKGWgqsVY3YpmbW92zkRZNwWOMMZFO4ufKy8uVlpamvhqieI/zM2B+UZieReMGDQpiSY2p1lItlM/ni5q9HQdrx66vOik1JS7S6cQ0GhTUJ9x1I+JTPAAAAIeiQQEAANahQQEAANahQQEAANYJ663um5SLDbCeOOeNcqYmPJtka3/cGZbzKN45Z0+8u83D3KIeQGNg0gdNgRUUAABgHRoUAABgHRoUAABgHRoUAABgHRoUAABgnaid4olvleEYU/PDj+G5Vqfjna/1zbdhuVbNpm/Cch4ARxemZhBrWEEBAADWoUEBAADWoUEBAADWoUEBAADWoUEBAADWidopHjcTOm6exeNJSnKMMT+VuUnJkbd5c8cY//79jjHxOe1cXa9m63eu4gBEPzfPx2lKTBXhSLGCAgAArEODAgAArEODAgAArEODAgAArBO1m2S9iYlhOY9/f4VjTGW/bo4xSW987OJazhtg3WDzK4BDsSkVsYYVFAAAYB0aFAAAYB0aFAAAYB0aFAAAYB0aFAAAYJ2oneJxw19V5Rzkce7Rkv6x0jHGm9TMMcbU1jrGxHXMcYyp2fi1YwyAo0tT3uqeiSE0BVZQAACAdWhQAACAdWhQAACAdWhQAACAdWhQAACAdaJ2isfNhI431/kZOt4fyhxj3Dz7xtWETuuWztdiQgdABDGhA1uwggIAAKxDgwIAAKxDgwIAAKxDgwIAAKxDgwIAAKwTtVM8bvhXr3OOMf7wXMzFeWq2l4TlUvEd2ruK85f84BjjdTNZ9N33rq4HIPo15TN93GCq6OjFCgoAALAODQoAALAODQoAALAODQoAALAODQoAALBOTE/xeBMTnYPinHs0b5vWjjGmvNwxpvanXc75uFCzZVtYziNJfiZ0gKMGEzGIJo22gvLMM8/o+OOPV7NmzdSzZ099/PHHjXUpADGCugHgoEZpUF555RVNnDhRkydP1urVq9WjRw8VFBRox44djXE5ADGAugHg5xqlQZk2bZrGjBmja6+9VqeccopmzZqlY445Rn/5y18a43IAYgB1A8DPhX0PSlVVlVatWqVJkyYFjnm9XuXn56uoqKhOfGVlpSorKwNf+3w+SVKNqiVzZLl4jYv+y0WM11/pGGP8VY4xtabaOR/AAjU68P9VY47wL6FLodYN6fC1o3xPmO4OHYNqqEFoROGuG2FvUH788UfV1tYqMzMz6HhmZqbWr19fJ37q1KmaMmVKneMf6s0jT8a5r3BnS5jOA0SZnTt3Ki0trdGvE2rdkA5fOzqc+W1jpBgjvol0AjgKhKtuRHyKZ9KkSZo4cWLg67KyMnXo0EFbt25tksIYDuXl5Wrfvr22bdum1NTUSKfjWjTmTc5Nw+fzKScnRxkZGZFO5bCoHZFBzk0jGnMOd90Ie4PSqlUrxcXFqbS0NOh4aWmpsrKy6sQnJSUpKSmpzvG0tLSo+R/loNTU1KjLWYrOvMm5aXi9TXOrpFDrhkTtiDRybhrRmHO46kbYq09iYqJyc3O1ZMmSwDG/368lS5YoLy8v3JcDEAOoGwAO1Si/4pk4caJGjx6ts846S+ecc44ef/xx7d27V9dee21jXA5ADKBuAPi5RmlQRo4cqR9++EH33HOPSkpKdPrpp+utt96qswGuPklJSZo8eXK9S7e2isacpejMm5ybRiRyPpK6IfE5NxVybhrkLHlMU80RAgAAuMTDAgEAgHVoUAAAgHVoUAAAgHVoUAAAgHVoUAAAgHWsa1CeeeYZHX/88WrWrJl69uypjz/+ONIpHda9994rj8cT9OratWuk0wrywQcfaPDgwcrOzpbH49GCBQuC3jfG6J577lHbtm3VvHlz5efna+PGjZFJ9t+ccr7mmmvqfO4DBw6MTLL/NnXqVJ199tlKSUlRmzZtNHToUG3YsCEopqKiQoWFhWrZsqWSk5M1fPjwOndObUpucu7bt2+dz/qGG26IUMaHF011Q6J2NBZqR9NoqtphVYPyyiuvaOLEiZo8ebJWr16tHj16qKCgQDt27Ih0aod16qmnavv27YHXhx9+GOmUguzdu1c9evTQM888U+/7Dz/8sJ588knNmjVLK1asUIsWLVRQUKCKioomzvT/OOUsSQMHDgz63F966aUmzLCuZcuWqbCwUMuXL9fixYtVXV2tAQMGaO/evYGYCRMm6PXXX9e8efO0bNkyFRcXa9iwYVbnLEljxowJ+qwffvjhCGVcv2isGxK1ozFQO+zJWQpD7TAWOeecc0xhYWHg69raWpOdnW2mTp0awawOb/LkyaZHjx6RTsM1SWb+/PmBr/1+v8nKyjKPPPJI4FhZWZlJSkoyL730UgQyrOvQnI0xZvTo0WbIkCERycetHTt2GElm2bJlxpgDn2tCQoKZN29eIObLL780kkxRUVGk0gxyaM7GGHP++eebm2++OXJJuRBtdcMYakdToHY0ncaqHdasoFRVVWnVqlXKz88PHPN6vcrPz1dRUVEEM/tlGzduVHZ2tjp16qSrrrpKW7dujXRKrm3evFklJSVBn3laWpp69uxp9WcuSUuXLlWbNm3UpUsX3Xjjjdq5c2ekUwri8/kkKfBUz1WrVqm6ujros+7atatycnKs+awPzfmgv/3tb2rVqpW6deumSZMmad++fZFIr17RWjckakekUDvCr7FqR6Pc6r4hfvzxR9XW1ta5rXVmZqbWr18foax+Wc+ePTVnzhx16dJF27dv15QpU3Teeefp888/V0pKSqTTc1RSUiJJ9X7mB9+z0cCBAzVs2DB17NhRX3/9te644w4NGjRIRUVFiouLi3R68vv9Gj9+vHr37q1u3bpJOvBZJyYmKj09PSjWls+6vpwl6corr1SHDh2UnZ2tTz/9VLfffrs2bNig//mf/4lgtv8nGuuGRO2IFGpH+DVm7bCmQYlGgwYNCvy5e/fu6tmzpzp06KBXX31V1113XQQzi21XXHFF4M+nnXaaunfvrhNOOEFLly5V//79I5jZAYWFhfr888+t21PwSw6X89ixYwN/Pu2009S2bVv1799fX3/9tU444YSmTjNmUDsig9oRfo1ZO6z5FU+rVq0UFxdXZ2dyaWmpsrKyIpRVaNLT03XSSSdp06ZNkU7FlYOfazR/5pLUqVMntWrVyorPfdy4cXrjjTf0/vvvq127doHjWVlZqqqqUllZWVC8DZ/14XKuT8+ePSXJis9aio26IVE7IoXacWQau3ZY06AkJiYqNzdXS5YsCRzz+/1asmSJ8vLyIpiZe3v27NHXX3+ttm3bRjoVVzp27KisrKygz7y8vFwrVqyIms9ckr777jvt3Lkzop+7MUbjxo3T/Pnz9d5776ljx45B7+fm5iohISHos96wYYO2bt0asc/aKef6rF27VpKs+f94LNQNidoRKdSOhmmy2nFEW2zD7OWXXzZJSUlmzpw5Zt26dWbs2LEmPT3dlJSURDq1et1yyy1m6dKlZvPmzeaf//ynyc/PN61atTI7duyIdGoBu3fvNmvWrDFr1qwxksy0adPMmjVrzJYtW4wxxjz44IMmPT3dLFy40Hz66admyJAhpmPHjmb//v1W5rx7925z6623mqKiIrN582bz7rvvmjPPPNN07tzZVFRURCznG2+80aSlpZmlS5ea7du3B1779u0LxNxwww0mJyfHvPfee2blypUmLy/P5OXlWZvzpk2bzH333WdWrlxpNm/ebBYuXGg6depkfvWrX0Us5/pEW90whtoRiZypHU2Xc7hqh1UNijHGPPXUUyYnJ8ckJiaac845xyxfvjzSKR3WyJEjTdu2bU1iYqI57rjjzMiRI82mTZsinVaQ999/30iq8xo9erQx5sC44N13320yMzNNUlKS6d+/v9mwYYO1Oe/bt88MGDDAtG7d2iQkJJgOHTqYMWPGRPw/RvXlK8nMnj07ELN//37z+9//3hx77LHmmGOOMZdeeqnZvn27tTlv3brV/OpXvzIZGRkmKSnJnHjiieaPf/yj8fl8Ecv5cKKpbhhD7YhEztSOpss5XLXD8++LAQAAWMOaPSgAAAAH0aAAAADr0KAAAADr0KAAAADr0KAAAADr0KAAAADr0KAAAADr0KAAAADr0KAAAADr0KAAAADr0KAAAADr/H9JeT/ABK+h+AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_tokens = source_vectorization(example_input_batch)\n",
    "print(example_tokens[:2, :])\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(example_tokens)\n",
    "plt.title('Token IDs')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(example_tokens != 0)\n",
    "plt.title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a76a6ae",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83f82c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(eng, spa):\n",
    "    eng = source_vectorization(eng)\n",
    "    spa = target_vectorization(spa)\n",
    "    return ({\"english\": eng, \"spanish\": spa[:, :-1]}, spa[:, 1:])\n",
    "\n",
    "def make_dataset(pairs, batch_size=BATCH_SIZE):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts)).batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048).prefetch(buffer_size=tf.data.AUTOTUNE).cache()\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds   = make_dataset(val_pairs)\n",
    "test_ds  = make_dataset(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6fe4315",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'english': <tf.Tensor: shape=(64, 25), dtype=int64, numpy=\n",
      "array([[   2,   98,  593, ...,    0,    0,    0],\n",
      "       [   2,    6, 2310, ...,    0,    0,    0],\n",
      "       [   2,   13,   12, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   2,   53,  444, ...,    0,    0,    0],\n",
      "       [   2,  144,    6, ...,    0,    0,    0],\n",
      "       [   2,    9,   59, ...,    0,    0,    0]], dtype=int64)>, 'spanish': <tf.Tensor: shape=(64, 25), dtype=int64, numpy=\n",
      "array([[   2,  357,  542, ...,    0,    0,    0],\n",
      "       [   2,   30, 2379, ...,    0,    0,    0],\n",
      "       [   2,    7,   15, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   2,   13,    5, ...,    0,    0,    0],\n",
      "       [   2,  106,   74, ...,    0,    0,    0],\n",
      "       [   2,   10,    9, ...,    0,    0,    0]], dtype=int64)>}\n",
      "tf.Tensor(\n",
      "[[ 357  542 7287 ...    0    0    0]\n",
      " [  30 2379    5 ...    0    0    0]\n",
      " [   7   15 4684 ...    0    0    0]\n",
      " ...\n",
      " [  13    5   65 ...    0    0    0]\n",
      " [ 106   74  801 ...    0    0    0]\n",
      " [  10    9  137 ...    0    0    0]], shape=(64, 25), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for example_input_batch, example_target_batch in train_ds.take(1):\n",
    "    print(example_input_batch)\n",
    "    print(example_target_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa6eb9a",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96621840",
   "metadata": {},
   "source": [
    "- ### RNN (GRU, seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e9c686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim  = 256#256\n",
    "latent_dim = 1024#1024\n",
    "\n",
    "# Encoder\n",
    "source = Input(shape=(MAX_SEQ_LENGTH,), dtype=\"int64\", name=\"english\")\n",
    "x = Embedding(input_dim=VOCAB_SIZE, output_dim=embed_dim, mask_zero=True)(source)\n",
    "enocoded_source = Bidirectional(GRU(latent_dim), merge_mode=\"sum\")(x)\n",
    "\n",
    "# Decoder\n",
    "past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = Embedding(input_dim=VOCAB_SIZE, output_dim=embed_dim, mask_zero=True)(past_target)\n",
    "x = GRU(latent_dim, return_sequences=True)(x, initial_state=enocoded_source)\n",
    "x = Dropout(0.5)(x)\n",
    "# x = Dense(256, activation=\"relu\")(x)\n",
    "next_target_pred = Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model([source, past_target], next_target_pred, name=\"RNN_seq2seq2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb84551c",
   "metadata": {},
   "source": [
    "- ### Transformer (encoder + decoder)\n",
    "![title](arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7854a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim  # Input and output dim\n",
    "        self.dense_dim = dense_dim  # Hidden dense dim\n",
    "        self.num_heads = num_heads  # Num heads for MultiHeadAttention\n",
    "        \n",
    "        self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_part = Sequential([\n",
    "            Dense(dense_dim, activation=\"relu\"),\n",
    "            Dense(embed_dim)], name=\"dense_part\")\n",
    "        self.layernorm_1 = LayerNormalization()\n",
    "        self.layernorm_2 = LayerNormalization()\n",
    "        \n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_out = self.attention(query=inputs, value=inputs, key=inputs, attention_mask=mask)\n",
    "        dense_input = self.layernorm_1(attention_out + inputs)\n",
    "        dense_out = self.dense_part(dense_input)\n",
    "        return self.layernorm_2(dense_input + dense_out)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "class TransformerDecoder(Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.supports_masking = True  # API Keras значит на выход будет маска\n",
    "        self.embed_dim = embed_dim  # Input and output dim\n",
    "        self.dense_dim = dense_dim  # Hidden dense dim\n",
    "        self.num_heads = num_heads  # Num heads for MultiHeadAttention\n",
    "        \n",
    "        self.attention_1 = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_part = Sequential([\n",
    "            Dense(dense_dim, activation=\"relu\"),\n",
    "            Dense(embed_dim)], name=\"dense_part\")\n",
    "        self.layernorm_1 = LayerNormalization()\n",
    "        self.layernorm_2 = LayerNormalization()\n",
    "        self.layernorm_3 = LayerNormalization()\n",
    "        \n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "        \n",
    "        attention_1_out = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask)\n",
    "        attention_1_out = self.layernorm_1(attention_1_out + inputs)\n",
    "        \n",
    "        attention_2_out = self.attention_2(\n",
    "            query=attention_1_out,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask)\n",
    "        attention_2_out = self.layernorm_2(attention_2_out + attention_2_out)\n",
    "        \n",
    "        dense_out = self.dense_part(attention_2_out)\n",
    "        out = self.layernorm_3(attention_2_out + dense_out)\n",
    "        return out\n",
    "    \n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)  # (batch, seq, emb)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask_falatten = tf.cast(i >= j, dtype=\"int32\")  # bool to (1 or 0)\n",
    "        mask = tf.reshape(mask_falatten, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(  # copy mask from 1 to batch_size\n",
    "            [tf.expand_dims(batch_size, -1),\n",
    "            tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        return tf.tile(mask, mult)\n",
    "        \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef434898",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.sequence_length = sequence_length  # Длина последовательности\n",
    "        self.input_dim = input_dim              # Всего токенов\n",
    "        self.output_dim = output_dim            # Размер выходного вектора (токен + позиция)\n",
    "        \n",
    "        self.token_embeddings = Embedding(input_dim=input_dim, output_dim=output_dim, mask_zero=True)  # mask_zero=True\n",
    "        self.position_embeddings = Embedding(input_dim=sequence_length, output_dim=output_dim)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions  # concatene\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dc09073",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "dense_dim = 2048\n",
    "num_heads = 2\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = PositionalEmbedding(input_dim=VOCAB_SIZE, output_dim=embed_dim, sequence_length=MAX_SEQ_LENGTH)(encoder_inputs)\n",
    "enocoded_source = TransformerEncoder(embed_dim=embed_dim, dense_dim=dense_dim, num_heads=num_heads)(x)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = PositionalEmbedding(input_dim=VOCAB_SIZE, output_dim=embed_dim, sequence_length=MAX_SEQ_LENGTH)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim=embed_dim, dense_dim=dense_dim, num_heads=num_heads)(x, enocoded_source)\n",
    "\n",
    "x = Dropout(0.5)(x)\n",
    "# x = Dense(256, activation=\"relu\")(x)\n",
    "decoder_outputs = Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"Tranformer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16efd83",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "808c9bae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Tranformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " english (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " spanish (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " positional_embedding_4 (Positi  (None, None, 256)   3846400     ['english[0][0]']                \n",
      " onalEmbedding)                                                                                   \n",
      "                                                                                                  \n",
      " positional_embedding_5 (Positi  (None, None, 256)   3846400     ['spanish[0][0]']                \n",
      " onalEmbedding)                                                                                   \n",
      "                                                                                                  \n",
      " transformer_encoder_2 (Transfo  (None, None, 256)   3155456     ['positional_embedding_4[0][0]'] \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " transformer_decoder_2 (Transfo  (None, None, 256)   5259520     ['positional_embedding_5[0][0]', \n",
      " rmerDecoder)                                                     'transformer_encoder_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, None, 256)    0           ['transformer_decoder_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, None, 15000)  3855000     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 19,962,776\n",
      "Trainable params: 19,962,776\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        f\"{model.name}.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=7),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.666,\n",
    "        min_lr=6e-5,\n",
    "        patience=2),\n",
    "#     tf.keras.callbacks.TensorBoard(\n",
    "#         log_dir=\"logs\",\n",
    "#         histogram_freq=2,\n",
    "#         write_images=True)\n",
    "]\n",
    "\n",
    "model.compile(optimizer=RMSprop(0.001),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9518fd",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f641d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1329/1329 [==============================] - 87s 63ms/step - loss: 1.6444 - accuracy: 0.3746 - val_loss: 1.4174 - val_accuracy: 0.4291 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1329/1329 [==============================] - 84s 63ms/step - loss: 1.4361 - accuracy: 0.4453 - val_loss: 1.2971 - val_accuracy: 0.4783 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1329/1329 [==============================] - 81s 61ms/step - loss: 1.3211 - accuracy: 0.4829 - val_loss: 1.2068 - val_accuracy: 0.5103 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1329/1329 [==============================] - 83s 62ms/step - loss: 1.2437 - accuracy: 0.5099 - val_loss: 1.1493 - val_accuracy: 0.5347 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 1.1798 - accuracy: 0.5326 - val_loss: 1.0990 - val_accuracy: 0.5539 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 1.1351 - accuracy: 0.5503 - val_loss: 1.0694 - val_accuracy: 0.5660 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1329/1329 [==============================] - 82s 61ms/step - loss: 1.1180 - accuracy: 0.5628 - val_loss: 1.0634 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 1.1172 - accuracy: 0.5716 - val_loss: 1.0666 - val_accuracy: 0.5816 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1329/1329 [==============================] - 84s 63ms/step - loss: 1.1071 - accuracy: 0.5796 - val_loss: 1.0637 - val_accuracy: 0.5842 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1329/1329 [==============================] - 82s 61ms/step - loss: 1.0818 - accuracy: 0.5947 - val_loss: 1.0507 - val_accuracy: 0.5925 - lr: 6.6600e-04\n",
      "Epoch 11/100\n",
      "1329/1329 [==============================] - 85s 64ms/step - loss: 1.0717 - accuracy: 0.6013 - val_loss: 1.0462 - val_accuracy: 0.5973 - lr: 6.6600e-04\n",
      "Epoch 12/100\n",
      "1329/1329 [==============================] - 87s 65ms/step - loss: 1.0654 - accuracy: 0.6053 - val_loss: 1.0377 - val_accuracy: 0.6015 - lr: 6.6600e-04\n",
      "Epoch 13/100\n",
      "1329/1329 [==============================] - 86s 65ms/step - loss: 1.0610 - accuracy: 0.6089 - val_loss: 1.0352 - val_accuracy: 0.6047 - lr: 6.6600e-04\n",
      "Epoch 14/100\n",
      "1329/1329 [==============================] - 85s 64ms/step - loss: 1.0549 - accuracy: 0.6124 - val_loss: 1.0353 - val_accuracy: 0.6049 - lr: 6.6600e-04\n",
      "Epoch 15/100\n",
      "1329/1329 [==============================] - 90s 68ms/step - loss: 1.0497 - accuracy: 0.6155 - val_loss: 1.0297 - val_accuracy: 0.6066 - lr: 6.6600e-04\n",
      "Epoch 16/100\n",
      "1329/1329 [==============================] - 84s 63ms/step - loss: 1.0431 - accuracy: 0.6189 - val_loss: 1.0264 - val_accuracy: 0.6081 - lr: 6.6600e-04\n",
      "Epoch 17/100\n",
      "1329/1329 [==============================] - 90s 67ms/step - loss: 1.0382 - accuracy: 0.6215 - val_loss: 1.0232 - val_accuracy: 0.6097 - lr: 6.6600e-04\n",
      "Epoch 18/100\n",
      "1329/1329 [==============================] - 86s 65ms/step - loss: 1.0330 - accuracy: 0.6240 - val_loss: 1.0232 - val_accuracy: 0.6099 - lr: 6.6600e-04\n",
      "Epoch 19/100\n",
      "1329/1329 [==============================] - 83s 62ms/step - loss: 1.0294 - accuracy: 0.6259 - val_loss: 1.0221 - val_accuracy: 0.6116 - lr: 6.6600e-04\n",
      "Epoch 20/100\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 1.0258 - accuracy: 0.6277 - val_loss: 1.0234 - val_accuracy: 0.6111 - lr: 6.6600e-04\n",
      "Epoch 21/100\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 1.0194 - accuracy: 0.6305 - val_loss: 1.0156 - val_accuracy: 0.6140 - lr: 6.6600e-04\n",
      "Epoch 22/100\n",
      "1329/1329 [==============================] - 83s 63ms/step - loss: 1.0163 - accuracy: 0.6320 - val_loss: 1.0140 - val_accuracy: 0.6141 - lr: 6.6600e-04\n",
      "Epoch 23/100\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 1.0104 - accuracy: 0.6340 - val_loss: 1.0157 - val_accuracy: 0.6145 - lr: 6.6600e-04\n",
      "Epoch 24/100\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 1.0087 - accuracy: 0.6355 - val_loss: 1.0132 - val_accuracy: 0.6152 - lr: 6.6600e-04\n",
      "Epoch 25/100\n",
      "1329/1329 [==============================] - 81s 61ms/step - loss: 1.0032 - accuracy: 0.6377 - val_loss: 1.0101 - val_accuracy: 0.6186 - lr: 6.6600e-04\n",
      "Epoch 26/100\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 0.9996 - accuracy: 0.6393 - val_loss: 1.0138 - val_accuracy: 0.6164 - lr: 6.6600e-04\n",
      "Epoch 27/100\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 0.9956 - accuracy: 0.6411 - val_loss: 1.0088 - val_accuracy: 0.6186 - lr: 6.6600e-04\n",
      "Epoch 28/100\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 0.9912 - accuracy: 0.6434 - val_loss: 1.0082 - val_accuracy: 0.6199 - lr: 6.6600e-04\n",
      "Epoch 29/100\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 0.9887 - accuracy: 0.6442 - val_loss: 1.0103 - val_accuracy: 0.6175 - lr: 6.6600e-04\n",
      "Epoch 30/100\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 0.9840 - accuracy: 0.6457 - val_loss: 1.0091 - val_accuracy: 0.6169 - lr: 6.6600e-04\n",
      "Epoch 31/100\n",
      "1329/1329 [==============================] - 84s 63ms/step - loss: 0.9648 - accuracy: 0.6562 - val_loss: 0.9996 - val_accuracy: 0.6247 - lr: 4.4356e-04\n",
      "Epoch 32/100\n",
      "1329/1329 [==============================] - 86s 64ms/step - loss: 0.9569 - accuracy: 0.6600 - val_loss: 0.9980 - val_accuracy: 0.6251 - lr: 4.4356e-04\n",
      "Epoch 33/100\n",
      "1329/1329 [==============================] - 83s 62ms/step - loss: 0.9537 - accuracy: 0.6610 - val_loss: 0.9950 - val_accuracy: 0.6258 - lr: 4.4356e-04\n",
      "Epoch 34/100\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 0.9490 - accuracy: 0.6631 - val_loss: 0.9945 - val_accuracy: 0.6257 - lr: 4.4356e-04\n",
      "Epoch 35/100\n",
      "1329/1329 [==============================] - 84s 63ms/step - loss: 0.9429 - accuracy: 0.6652 - val_loss: 0.9960 - val_accuracy: 0.6255 - lr: 4.4356e-04\n",
      "Epoch 36/100\n",
      "1329/1329 [==============================] - 83s 62ms/step - loss: 0.9415 - accuracy: 0.6659 - val_loss: 0.9981 - val_accuracy: 0.6241 - lr: 4.4356e-04\n",
      "Epoch 37/100\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 0.9302 - accuracy: 0.6735 - val_loss: 0.9942 - val_accuracy: 0.6283 - lr: 2.9541e-04\n",
      "Epoch 38/100\n",
      "1329/1329 [==============================] - 87s 66ms/step - loss: 0.9258 - accuracy: 0.6761 - val_loss: 0.9974 - val_accuracy: 0.6289 - lr: 2.9541e-04\n",
      "Epoch 39/100\n",
      "1329/1329 [==============================] - 84s 63ms/step - loss: 0.9237 - accuracy: 0.6773 - val_loss: 0.9963 - val_accuracy: 0.6280 - lr: 2.9541e-04\n",
      "Epoch 40/100\n",
      "1329/1329 [==============================] - 83s 62ms/step - loss: 0.9164 - accuracy: 0.6822 - val_loss: 0.9957 - val_accuracy: 0.6302 - lr: 1.9674e-04\n",
      "Epoch 41/100\n",
      " 163/1329 [==>...........................] - ETA: 1:09 - loss: 0.9143 - accuracy: 0.6819"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#53 66 67.5   77s\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=val_ds, callbacks=callbacks, epochs=100) #53 66 67.5   77s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b04c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d83383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c07da82c",
   "metadata": {},
   "source": [
    "### Test models in translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a97c095",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "You shouldn't have lied to me.\n",
      "[START] no que deberias me [UNK] . . [END]\n",
      "-\n",
      "Don't go there.\n",
      "[START] no a alli estar . alli [END]\n",
      "-\n",
      "Food should be chewed before being swallowed.\n",
      "[START] la comida comida antes antes de de [UNK] la . [UNK] [END]\n",
      "-\n",
      "He was accompanied by his wife.\n",
      "[START] fue estaba por [UNK] su . madre [END]\n",
      "-\n",
      "I am tired of the work.\n",
      "[START] estoy cansado de del el trabajo trabajo . . [END]\n",
      "-\n",
      "I don't want to go to work today.\n",
      "[START] no que quiero trabajar ir . . [END]\n",
      "-\n",
      "I agreed.\n",
      "[START] yo . . [END]\n",
      "-\n",
      "I would like to go to America one day.\n",
      "[START] me una gustaria escuela ir en en un un dia dia . . [END]\n",
      "-\n",
      "Didn't you hear the doorbell?\n",
      "[START] ¿ no que le [UNK] [UNK] ? ? [END]\n",
      "-\n",
      "How you've grown!\n",
      "[START] como que has ! [UNK] [END]\n",
      "-\n",
      "Tom understands what it takes to survive.\n",
      "[START] tom que lo esta que haciendo te . [UNK] [END]\n",
      "-\n",
      "You have many friends.\n",
      "[START] tienes muchos amigos amigos . . [END]\n",
      "-\n",
      "It's very clean.\n",
      "[START] es muy muy . . [END]\n",
      "-\n",
      "On my way here, the strong wind blew my umbrella inside out.\n",
      "[START] en de una aqui vez , , el el paraguas paraguas en en el el paraguas paraguas . . [END]\n",
      "-\n",
      "I don't know how old I am.\n",
      "[START] no que como un yo joven . . [END]\n",
      "-\n",
      "I barely know Tom.\n",
      "[START] apenas se saber . a [END]\n",
      "-\n",
      "Don't ask me for forgiveness. What's been done has been done.\n",
      "[START] no que te no hace es lo que que ha el sido . . [END]\n",
      "-\n",
      "I'll call her immediately.\n",
      "[START] le a [UNK] sus . . [END]\n",
      "-\n",
      "If anyone can do it, it's you.\n",
      "[START] si alguien puede lo hacer que . es [END]\n",
      "-\n",
      "Long time, no see.\n",
      "[START] yo de que que ver quiere . . [END]\n"
     ]
    }
   ],
   "source": [
    "# model = load_model(\"RNN_seq2seq.keras\")  # Tranformer RNN_seq2seq\n",
    "# print(f\"Test acc: {model.evaluate(test_ds)[1]:.3f}\")\n",
    "\n",
    "def decode_sequence(input_sentence, is_transfomer=False):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[START]\"\n",
    "    for i in range(MAX_SEQ_LENGTH):\n",
    "        tokenized_target_sentence = target_vectorization([decoded_sentence])\n",
    "        if is_transfomer:\n",
    "            tokenized_target_sentence = tokenized_target_sentence[:, :-1]\n",
    "        next_token_predictions = model.predict([tokenized_input_sentence, tokenized_target_sentence], verbose=0)\n",
    "        sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[END]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in train_pairs]  # train_pairs test_pairs\n",
    "for _ in range(20):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1ffdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da33121c",
   "metadata": {},
   "source": [
    "#### Another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f949691",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, max_sentence_len=50, embedding_size=256, dtype=tf.float32, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        if not embedding_size % 2 == 0:\n",
    "            raise ValueError(\"The `embedding_size` must be even.\")\n",
    "\n",
    "        p, i = np.meshgrid(np.arange(max_sentence_len), np.arange(embedding_size // 2))\n",
    "        pos_emb = np.empty((1, max_sentence_len, embedding_size))\n",
    "        pos_emb[:, :, 0::2] = np.sin(p / 10_000 ** (2 * i / embedding_size)).T\n",
    "        pos_emb[:, :, 1::2] = np.cos(p / 10_000 ** (2 * i / embedding_size)).T\n",
    "        self.positional_embedding = tf.constant(pos_emb.astype(self.dtype))\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_max_length = tf.shape(inputs)[1]\n",
    "        return inputs + self.positional_embedding[:, :batch_max_length]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
